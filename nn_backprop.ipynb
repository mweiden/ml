{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def flat_for(a, f):\n",
    "    a = a.reshape(-1)\n",
    "    for i, v in enumerate(a):\n",
    "        a[i] = f(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10640bfd0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaHlIzoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10373bc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-5, 5, 20)\n",
    "plt.plot(xs, [sigmoid(x) for x in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    basic neural network with training via backpropagation (non-vectorized)\n",
    "        follows notation from Andrew Ng's Machine Learning Coursera Course (week 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.epsilon = 0.25\n",
    "        np.random.seed(0)\n",
    "        # one row is added for bias term\n",
    "        transitions = [layer_sizes[i:i+2] for i in range(0, len(layer_sizes)-1)]\n",
    "        self.layer_dim_edges = [(t[1],t[0]+1) for t in transitions]\n",
    "        self.thetas      = [np.random.rand(t[0], t[1]) * 2 * self.epsilon - self.epsilon for t in self.layer_dim_edges]\n",
    "        self.lambda_val  = 0.0001\n",
    "        self.num_layers = len(self.thetas)\n",
    "        print \"layer theta initialization:\"\n",
    "        for theta in self.thetas:\n",
    "            print theta\n",
    "            print\n",
    "            \n",
    "    def unflatten_thetas(self, flat):\n",
    "        current = 0\n",
    "        unflattened = []\n",
    "        for dims in self.layer_dim_edges:\n",
    "            count = dims[0] * dims[1]\n",
    "            unflattened += np.reshape(flat[current:current+count], dims)\n",
    "            current += count\n",
    "        return unflattened\n",
    "    \n",
    "    def flatten(self, ary):\n",
    "        return np.hstack([np.asarray(ele.flatten()) for ele in ary])\n",
    "    \n",
    "    def train(self, xs, ys):\n",
    "        m = float(xs.shape[0])\n",
    "        def cost(new_thetas_flat):\n",
    "            # compute j value\n",
    "            j = self.lambda_val / (2.0 * m) * np.sum(np.power(new_thetas_flat, 2))\n",
    "            for i in range(xs.shape[0]):\n",
    "                h_theta = self.forward_propagate(xs[i], thetas = self.unflatten_thetas(new_thetas_flat))[-1]\n",
    "                j += ys[i] * h_theta + (1.0 - ys[i]) * np.log(1.0 - h_theta)\n",
    "            return j\n",
    "        def cost_prime(new_thetas_flat):\n",
    "            # compute new D\n",
    "            D = self.back_propagate(xs, ys, thetas = self.unflatten_thetas(new_thetas_flat))\n",
    "            D = flatten(D)\n",
    "            return D\n",
    "        return opt.fmin_l_bfgs_b(cost, self.flatten(self.thetas), fprime=cost_prime)\n",
    "            \n",
    "    def forward_propagate(self, x, thetas = None):\n",
    "        thetas = thetas if thetas != None else self.thetas\n",
    "        state = x\n",
    "        activations = [self.add_bias_w(x)]\n",
    "        for theta in thetas[:-1]:\n",
    "            state = self.layer_step(theta, activations[-1])\n",
    "            flat_for(state, sigmoid)\n",
    "            activations.append(self.add_bias_w(state))\n",
    "        activations.append(self.layer_step(thetas[-1], activations[-1]))\n",
    "        return activations\n",
    "    \n",
    "    def compute_gradient(self, x, y, thetas = None):\n",
    "        thetas = thetas if thetas != None else self.thetas\n",
    "        activations = self.forward_propagate(x.T)\n",
    "        deltas = [None] * (self.num_layers+1)\n",
    "        grad = [None] * self.num_layers\n",
    "        deltas[-1] = activations[-1] - y.T\n",
    "        for l in range(self.num_layers-1, 0, -1):\n",
    "            deltas[l] = np.multiply(thetas[l].T.dot(deltas[l+1]),\n",
    "                                    np.multiply(activations[l], 1.0 - activations[l]))\n",
    "        for l in range(0, self.num_layers):\n",
    "            # remove the change in bias term activation when propagating to earlier layers\n",
    "            delta_sel = deltas[l+1] if l == self.num_layers-1 else deltas[l+1][1:,:]\n",
    "            grad[l] = delta_sel.dot(activations[l].T)\n",
    "        return grad\n",
    "    \n",
    "    def back_propagate(self, xs, ys):\n",
    "        assert(xs.shape[0] == ys.shape[0])\n",
    "        m = float(len(xs))\n",
    "        D = self.compute_gradient(xs[0], ys[0])\n",
    "        for x, y in zip(xs[1:], ys[1:]):\n",
    "            xyD = self.compute_gradient(x, y)\n",
    "            for l in range(0, self.num_layers):\n",
    "                D[l] += xyD[l]\n",
    "        for l in range(0, self.num_layers):\n",
    "            D[l] /= m\n",
    "        D[l][:,1:] += self.lambda_val * self.thetas[l][:,1:]\n",
    "        return D\n",
    "    \n",
    "    def update(self, D):\n",
    "        for i in range(0,len(self.thetas)):\n",
    "            self.thetas[i] -= D[i]\n",
    "    \n",
    "    def add_bias_w(self, v):\n",
    "        return np.vstack([np.matrix([[1]]), v])\n",
    "    \n",
    "    # theta(nodes_ldim x input_dim) * x_or_z(input_dim x 1)\n",
    "    def layer_step(self, theta, x_or_z):\n",
    "        return theta.dot(x_or_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer theta initialization:\n",
      "[[ 0.02440675  0.10759468  0.05138169]\n",
      " [ 0.02244159 -0.0381726   0.07294706]]\n",
      "\n",
      "[[-0.03120639  0.1958865   0.23183138]]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-736ebfd6940a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#D = nn.back_propagate(xs, ys)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#    nn.update(D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-84c0663dbb78>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, xs, ys)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcost_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 187\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    188\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    189\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-84c0663dbb78>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(new_thetas_flat)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_val\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_thetas_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mh_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten_thetas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_thetas_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_theta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-84c0663dbb78>\u001b[0m in \u001b[0;36munflatten_thetas\u001b[0;34m(self, flat)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_dim_edges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0munflattened\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munflattened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (2,3) "
     ]
    }
   ],
   "source": [
    "layer_sizes = [2, 2, 1]\n",
    "nn = NeuralNetwork(layer_sizes)\n",
    "\n",
    "np.random.seed(0)\n",
    "#for i in range(0,10000):\n",
    "xs = np.matrix([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]] * 2500) + np.random.randn(10000,2) * 0.05\n",
    "ys = np.matrix([[0.0], [1.0], [0.0], [1.0]] * 2500)\n",
    "nn.train(xs,ys)\n",
    "#D = nn.back_propagate(xs, ys)\n",
    "#    nn.update(D)\n",
    "\n",
    "#print \"new thetas:\"\n",
    "#for theta in nn.thetas:\n",
    "#    print theta\n",
    "#    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 1.0], [1.0, 0.0], [0.0, 0.0], [1.0, 1.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[matrix([[ 0.99669106]]),\n",
       " matrix([[ 1.0056668]]),\n",
       " matrix([[-0.01370508]]),\n",
       " matrix([[-0.01048806]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = [[0.0,1.0],[1.0,0.0],[0.0,0.0],[1.0,1.0]]\n",
    "print tests\n",
    "\n",
    "[nn.forward_propagate(np.matrix([t]).T)[-1] for t in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(matrix([[ 0.,  1.]]), matrix([[ 1.]])),\n",
       " (matrix([[ 1.,  0.]]), matrix([[ 1.]])),\n",
       " (matrix([[ 0.,  0.]]), matrix([[ 0.]])),\n",
       " (matrix([[ 1.,  1.]]), matrix([[ 0.]]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(np.matrix(tests),np.matrix([[1.0,1.0,0.0,0.0]]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(np.asarray(np.matrix([[1,3],[1,2]]).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
